{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YoloV2 - detection de chiffres avec le MNIST\n",
    "\n",
    "Notebook de correction du TP.\n",
    "\n",
    "## Génération des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PATH_DATASETS = \"datasets/\"\n",
    "PATH_MNIST = os.path.join(PATH_DATASETS, \"source\")\n",
    "PATH_TRAIN_SET = os.path.join(PATH_DATASETS, \"train_set\")\n",
    "PATH_VAL_SET = os.path.join(PATH_DATASETS, \"validation_set\")\n",
    "\n",
    "if not os.path.exists(PATH_DATASETS):\n",
    "    os.mkdir(PATH_DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:12<00:00, 69.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 71.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.generate_dataset import generate_dataset\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "\n",
    "print(\"Generating train set...\")\n",
    "generate_dataset(\n",
    "    source_dataset=MNIST(PATH_MNIST, train=True, download=True),\n",
    "    path_dataset=PATH_TRAIN_SET,\n",
    "    sample_count=5000,\n",
    "    image_width=512,\n",
    "    image_height=512,\n",
    "    min_objects_per_image=0,\n",
    "    max_objects_per_image=20,\n",
    "    noise_strength=0\n",
    ")\n",
    "\n",
    "print(\"Generating test set...\")\n",
    "generate_dataset(\n",
    "    source_dataset=MNIST(PATH_MNIST, train=False, download=True),\n",
    "    path_dataset=PATH_VAL_SET,\n",
    "    sample_count=500,\n",
    "    image_width=512,\n",
    "    image_height=512,\n",
    "    min_objects_per_image=0,\n",
    "    max_objects_per_image=20,\n",
    "    noise_strength=0\n",
    ")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.display_boxes import display_random_dataset_samples\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "images = display_random_dataset_samples(\n",
    "    path_dataset=PATH_TRAIN_SET,\n",
    "    sample_count=1\n",
    ")\n",
    "\n",
    "for image in images:\n",
    "    plt.imshow(image)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.mobilenetv2 import mobilenet_v2, MobileNet_V2_Weights\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Tensor, nn\n",
    "import numpy as np\n",
    "\n",
    "from yolo.dataset import YoloDataset, collate_fn\n",
    "from yolo.metrics import CocoEvaluator\n",
    "from yolo.post_processor import non_maximum_suppression, filter_by_score\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'activation\n",
    "\n",
    "Le format du tenseur `encoded_boxes` avant l'activation:\n",
    "- `x[..., 0] = x` : position x du centre de la boîte par rapport a sa cellule.\n",
    "- `x[..., 1] = y` : position y du centre de la boîte par rapport a sa cellule.\n",
    "- `x[..., 2] = w` : largeur de la boîte par rapport a son prior.\n",
    "- `x[..., 3] = h` : hauteur de la boîte par rapport a son prior.\n",
    "- `x[..., 4] = L` : score d'objectivité (probabilité que la boîte contienne un objet, logit pré-activation).\n",
    "- `x[..., 5:] = Lc` : probabilités conditionelle des classes (logit pré-activation).\n",
    "\n",
    "Le format du tenseur de sortie:\n",
    "- `y[..., 0] = x` : position x du centre de la boîte par rapport a la feature map.\n",
    "- `y[..., 1] = y` : position y du centre de la boîte par rapport a la feature map.\n",
    "- `y[..., 2] = w` : largeur de la boîte par rapport a la feature map.\n",
    "- `y[..., 3] = h` : hauteur de la boîte par rapport a la feature map.\n",
    "- `y[..., 4] = P` : score d'objectivité.\n",
    "- `y[..., 5:] = C` : probabilités conditionelle des classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_boxes(\n",
    "    encoded_boxes: Tensor,\n",
    "    priors: Tensor,\n",
    "    input_size: tuple[int, int]\n",
    ") -> Tensor:\n",
    "    \"\"\"Decode the output bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        encoded_boxes (Tensor): Encoded bounding boxes.\n",
    "        priors (Tensor): Priors of shape (P x 2).\n",
    "        input_size (tuple[int, int]): Shape of the input image.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Decoded bounding boxes.\n",
    "    \"\"\"\n",
    "    grid_h, grid_w = encoded_boxes.shape[1:3]\n",
    "    scale_h, scale_w = input_size[0] / grid_h, input_size[1] / grid_w\n",
    "\n",
    "    # The predicted coordinates are local to the cell of the prediction, meaning it\n",
    "    # is a value between 0 and 1, positioning the center of the box within that\n",
    "    # cell. The goal of the activation function is to get the coordinates of the box\n",
    "    # in relative to the grid (i.e. x in [0 WG[ and y in [0 HG[). To do this, first\n",
    "    # we create a tensor in which each cell contains its own coordinates within the\n",
    "    # grid (shape: (1 x HG x WG x 1 x 2)).\n",
    "    cell_w = torch.arange(0, grid_w, dtype=torch.float32).to(encoded_boxes.device)\n",
    "    cell_h = torch.arange(0, grid_h, dtype=torch.float32).to(encoded_boxes.device)\n",
    "    cell_grid = torch.stack(torch.meshgrid(cell_w, cell_h, indexing=\"ij\"))\n",
    "    cell_grid = torch.swapaxes(cell_grid, 0, -1)\n",
    "    cell_grid = torch.reshape(cell_grid, shape=(1, grid_h, grid_w, 1, 2))\n",
    "\n",
    "    # Then, we add the coordinates of the cell to the coordinates of the box after\n",
    "    # applying the sigmoid function (shape: (BS x HG x WG x P x 2)).\n",
    "    predicted_xy = encoded_boxes[..., :2]\n",
    "    predicted_xy = torch.sigmoid(predicted_xy)\n",
    "    predicted_xy = cell_grid + predicted_xy\n",
    "\n",
    "    # The predicted dimension of the box is relative to the associated prior. The\n",
    "    # activation function used here is the exponential function, meaning that a\n",
    "    # predicted size of 0 pre-activation will give the size of the prior (shape:\n",
    "    # (BS x HG x WG x P x 2)).\n",
    "    predicted_wh = encoded_boxes[..., 2:4]\n",
    "    predicted_wh = torch.exp(predicted_wh)\n",
    "    predicted_wh = priors * predicted_wh\n",
    "\n",
    "    # Since the priors are relative to the input image size, we have to rescale the\n",
    "    # boxes to the grid.\n",
    "    predicted_wh[..., 0] /= scale_w\n",
    "    predicted_wh[..., 1] /= scale_h\n",
    "\n",
    "    # The predicted objectness is merely obtained by applying the sigmoid function\n",
    "    # to the logit. This probability indicates whether the box actually contains an\n",
    "    # object. The loss function used by YOLOv2 will make this value quantify the\n",
    "    # quality of the box (shape: (BS x HG x WG x P x 1)).\n",
    "    predicted_objectness = encoded_boxes[..., 4]\n",
    "    predicted_objectness = torch.sigmoid(predicted_objectness)\n",
    "    predicted_objectness = predicted_objectness.unsqueeze(dim=-1)\n",
    "\n",
    "    # Finally, the conditional probability vector is obtained by applying the\n",
    "    # softmax function (shape: (BS x HG x WG x P x C])).\n",
    "    predicted_probabilities = encoded_boxes[..., 5:]\n",
    "    predicted_probabilities = torch.softmax(predicted_probabilities, dim=-1)\n",
    "\n",
    "    # The output tensor is then assembled by concatenating the previously computed\n",
    "    # tensors (shape: (BS x HG x WG x P x (5+C))).\n",
    "    decoded_boxes = torch.cat([\n",
    "        predicted_xy,\n",
    "        predicted_wh,\n",
    "        predicted_objectness,\n",
    "        predicted_probabilities\n",
    "    ], axis=-1)\n",
    "\n",
    "    return decoded_boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition de la tête de detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloDetectionHead(nn.Module):\n",
    "    \"\"\"Yolo detection head.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        priors: Tensor | np.ndarray,\n",
    "        num_classes: int\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the detection head.\n",
    "\n",
    "        Args:\n",
    "            in_channels (int): Depth of the input feature map.\n",
    "            priors (Tensor | np.ndarray): Pre-computed priors.\n",
    "            num_classes (int): Number of output class.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "        self.prior_count = priors.shape[0]\n",
    "\n",
    "        if isinstance(priors, np.ndarray):\n",
    "            priors = torch.from_numpy(priors)\n",
    "\n",
    "        self.register_buffer(\"priors\", priors)\n",
    "\n",
    "        self.convolution_head = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=self.prior_count * (5 + num_classes),\n",
    "            kernel_size=1\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        feature_maps: Tensor,\n",
    "        input_size: tuple[int, int]\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Compute bounding boxes based on the given feature map.\n",
    "\n",
    "        Args:\n",
    "            feature_maps (Tensor): Feature extractor output tensor.\n",
    "            input_size (tuple[int, int]): Input sizes of each image of the batch.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Decoded bounding boxes.\n",
    "        \"\"\"\n",
    "        encoded_boxes = self.convolution_head(feature_maps)\n",
    "\n",
    "        # The decode function expects to receive a BS x HG x WG x P x (5+C) tensor.\n",
    "        # Since torch uses a channels first format, we have a BS x [B*(5+C)] x HG x WG\n",
    "        # tensor at this step, so we have to move the axes around. First, we switch from\n",
    "        # channels first to channels last and then split the channels into priors x\n",
    "        # classes.\n",
    "        encoded_boxes_reshaped = torch.moveaxis(encoded_boxes, 1, -1)\n",
    "        encoded_boxes_reshaped = torch.reshape(encoded_boxes_reshaped, shape=(\n",
    "            *encoded_boxes_reshaped.shape[:-1], self.prior_count, 5 + self.num_classes\n",
    "        ))\n",
    "\n",
    "        decoded_boxes = decode_boxes(encoded_boxes_reshaped, self.priors, input_size)\n",
    "\n",
    "        return decoded_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de coût\n",
    "\n",
    "Formats des tenseurs de sorties et GT (shape: BS x HG x WG x P x (5+C)):\n",
    "- `y[..., 0] = x` : position x du centre de la boîte par rapport a la feature map.\n",
    "- `y[..., 1] = y` : position y du centre de la boîte par rapport a la feature map.\n",
    "- `y[..., 2] = w` : largeur de la boîte par rapport a la feature map.\n",
    "- `y[..., 3] = h` : hauteur de la boîte par rapport a la feature map.\n",
    "- `y[..., 4] = P` : score d'objectivité.\n",
    "- `y[..., 5:] = C` : probabilités conditionelle des classes.\n",
    "\n",
    "Pour les GT, toutes les valeurs sont à 0 si il n'y pas de boîte dans la cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_yolo(predicted: Tensor, ground_truth: Tensor) -> Tensor:\n",
    "    \"\"\"Compute the Yolo loss.\n",
    "\n",
    "    Args:\n",
    "        predicted (Tensor): The predicted tensor.\n",
    "        ground_truth (Tensor): The ground truth tensor.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The loss tensor.\n",
    "    \"\"\"\n",
    "    # First, we split the predicted tensors to retrieve the coordinates and the\n",
    "    # conditional probabilities.\n",
    "    predicted_xy = predicted[..., :2]  # (BS x HG x WG x P x 2)\n",
    "    predicted_wh = predicted[..., 2:4]  # (BS x HG x WG x P x 2)\n",
    "    predicted_objectness = predicted[..., 4]  # (BS x HG x WG x B)\n",
    "    predicted_probabilities = predicted[..., 5:]  # (BS x HG x WG x P x C)\n",
    "\n",
    "    # Same for the ground truth tensors.\n",
    "    true_xy = ground_truth[..., :2]  # (BS x HG x WG x P x 2)\n",
    "    true_wh = ground_truth[..., 2:4]  # (BS x HG x WG x P x 2)\n",
    "    true_objectness = ground_truth[..., 4]  # (BS x HG x WG x B)\n",
    "    true_probabilities = ground_truth[..., 5:]  # (BS x HG x WG x P x C)\n",
    "\n",
    "    # Position error: a simple square error between the predicted and ground truth\n",
    "    # positions.\n",
    "    diff_xy = torch.square(predicted_xy - true_xy)\n",
    "    diff_xy = torch.sum(diff_xy, dim=-1)\n",
    "    diff_xy = diff_xy * true_objectness\n",
    "\n",
    "    # Dimension error: a square error between the square roots of the predicted and\n",
    "    # ground truth dimensions.\n",
    "    diff_wh = torch.square(torch.sqrt(predicted_wh) - torch.sqrt(true_wh))\n",
    "    diff_wh = torch.sum(diff_wh, dim=-1)\n",
    "    diff_wh = diff_wh * true_objectness\n",
    "\n",
    "    # The following operations consists in determining the IOU between the predicted and\n",
    "    # ground truth boxes. First, we compute the position of top-left and bottom-right\n",
    "    # corners of the predicted boxes.\n",
    "    predicted_x0_y0 = predicted_xy - predicted_wh / 2\n",
    "    predicted_x1_y1 = predicted_xy + predicted_wh / 2\n",
    "\n",
    "    # Same goes for the ground truth boxes.\n",
    "    true_x0_y0 = true_xy - true_wh / 2\n",
    "    true_x1_y1 = true_xy + true_wh / 2\n",
    "\n",
    "    # Then we compute the coordinates of the intersection between the predicted and\n",
    "    # ground truth boxes.\n",
    "    intersection_x0_y0 = torch.maximum(predicted_x0_y0, true_x0_y0)\n",
    "    intersection_x1_y1 = torch.minimum(predicted_x1_y1, true_x1_y1)\n",
    "\n",
    "    # Using the coordinates, we can deduce the dimensions of the intersection.\n",
    "    # If the intersection is empty, at least one of the dimension will be negative. By\n",
    "    # setting it to zero, the intersection area will be zero.\n",
    "    intersection_wh = intersection_x1_y1 - intersection_x0_y0\n",
    "    intersection_wh = torch.clamp(intersection_wh, min=0)\n",
    "\n",
    "    # Then, we compute the intersection area between the predicted and ground truth\n",
    "    # boxes.\n",
    "    intersection_area = intersection_wh[..., 0] * intersection_wh[..., 1]\n",
    "\n",
    "    # To compute the IOU we also need to compute the union area.\n",
    "    predicted_area = predicted_wh[..., 0] * predicted_wh[..., 1]\n",
    "    true_area = true_wh[..., 0] * true_wh[..., 1]\n",
    "    union_area = predicted_area + true_area - intersection_area\n",
    "\n",
    "    # Finally, we compute the IOU between the predicted and ground truth boxes.\n",
    "    iou_scores = intersection_area / union_area\n",
    "\n",
    "    # Objectness error: a square error between the predicted objectness and the IOU\n",
    "    # between the boxes. This means that the objectness will tend to quantify the\n",
    "    # quality of the predicted box.\n",
    "    diff_objectness = torch.square(predicted_objectness - iou_scores)\n",
    "    diff_objectness = diff_objectness * true_objectness\n",
    "\n",
    "    # No objectness error: if the predicted box does not contain an object, the\n",
    "    # objectness should tend to zero.\n",
    "    diff_no_object = torch.square(predicted_objectness)\n",
    "    diff_no_object = diff_no_object * (1 - true_objectness)\n",
    "\n",
    "    # Classification error: a square error between the predicted and ground truth\n",
    "    # conditional probabilities. Note that any kind of classification loss can be used\n",
    "    # such as the binary cross-entropy.\n",
    "    diff_classification = torch.square(predicted_probabilities - true_probabilities)\n",
    "    diff_classification = torch.sum(diff_classification, dim=-1)\n",
    "    diff_classification = diff_classification * true_objectness\n",
    "\n",
    "    # The total loss is the weighted sum of all the previously computed errors.\n",
    "    diff = (\n",
    "        5 * diff_xy +\n",
    "        5 * diff_wh +\n",
    "        diff_objectness +\n",
    "        diff_no_object +\n",
    "        diff_classification\n",
    "    )\n",
    "\n",
    "    diff = torch.sum(diff, dim=(1, 2, 3))\n",
    "    loss = torch.mean(diff)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yolo.detection_head import YoloDetectionHead\n",
    "from yolo.ground_truth import YoloAnnotation, generate_ground_truth_tensors\n",
    "from yolo.loss_fn import loss_yolo\n",
    "from yolo.post_processor import DetectionResult, decode_boxes as box_tensor_to_box_list\n",
    "\n",
    "class YoloDetector(nn.Module):\n",
    "    \"\"\"Yolo detector model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: nn.Module,\n",
    "        priors: np.ndarray,\n",
    "        num_classes: int,\n",
    "        feature_map_depth: int = 1280\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize the model.\n",
    "\n",
    "        Args:\n",
    "            backbone (nn.Module): Feature extractor.\n",
    "            priors (np.ndarray): Model priors.\n",
    "            num_classes (int): Number of output class.\n",
    "            feature_map_depth (int): Depth of the feature extractor output.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.priors = priors\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.detection_head = YoloDetectionHead(feature_map_depth, priors, num_classes)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        images: Tensor,\n",
    "        targets: list[list[YoloAnnotation]] | None = None\n",
    "    ) -> Tensor | list[DetectionResult]:\n",
    "        \"\"\"Run the detector.\n",
    "\n",
    "        This function behavior differ between training and evaluation.\n",
    "        - when training, the targets (ground truth) must be supplied, and the loss is\n",
    "          directly returned.\n",
    "        - when not training, the decoded bounding boxes are returned (the boxes are not\n",
    "          filtered yet, so more post-processing such as NMS may be required).\n",
    "        This is done this way since it is how it is done in the torchvision library.\n",
    "\n",
    "        Args:\n",
    "            images (Tensor): Input images (must be batched).\n",
    "            targets (list[list[YoloAnnotation]], optional): Used in training mode, the\n",
    "                ground truth values.\n",
    "\n",
    "        Returns:\n",
    "            Tensor | list[DetectionResult]: Either the loss over the batch in training\n",
    "                mode, or the detected boxes.\n",
    "        \"\"\"\n",
    "        input_size = images.shape[2:]\n",
    "        batched_box_tensors = self.detection_head(self.backbone(images), input_size)\n",
    "\n",
    "        if self.training:\n",
    "            assert targets is not None, \"Targets are required when training.\"\n",
    "\n",
    "            ground_truth = generate_ground_truth_tensors(\n",
    "                annotations=targets,\n",
    "                priors=self.priors,\n",
    "                input_size=input_size,\n",
    "                grid_size=batched_box_tensors.shape[1:3],\n",
    "                num_classes=self.detection_head.num_classes\n",
    "            ).to(images.device)\n",
    "\n",
    "            return loss_yolo(batched_box_tensors, ground_truth)\n",
    "\n",
    "        return [\n",
    "            box_tensor_to_box_list(box_tensor, input_size)\n",
    "            for box_tensor in batched_box_tensors\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des datasets et calcul des priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors utilisés:\n",
      "[[12.94792396 19.99994168]\n",
      " [ 6.51933702 20.        ]\n",
      " [18.3101176  19.56420654]]\n"
     ]
    }
   ],
   "source": [
    "path_train_annotations = os.path.join(PATH_TRAIN_SET, \"annotations.json\")\n",
    "path_train_images = os.path.join(PATH_TRAIN_SET, \"images\")\n",
    "\n",
    "path_val_annotations = os.path.join(PATH_VAL_SET, \"annotations.json\")\n",
    "path_val_images = os.path.join(PATH_VAL_SET, \"images\")\n",
    "\n",
    "train_dataset = YoloDataset(path_train_annotations, path_train_images)\n",
    "val_dataset = YoloDataset(path_val_annotations, path_val_images)\n",
    "\n",
    "priors = train_dataset.get_priors(cluster_count=3)\n",
    "\n",
    "print(\"Priors utilisés:\")\n",
    "print(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création du modèle\n",
    "\n",
    "On utilise le feature extractor de MobileNetV2, il a l'avantage d'être plutot léger. Sa feature map contient 1280 caractéristiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YoloDetector(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (detection_head): YoloDetectionHead(\n",
       "    (convolution_head): Conv2d(1280, 45, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector = YoloDetector(\n",
    "    backbone=mobilenet_v2(\n",
    "        weights=MobileNet_V2_Weights.DEFAULT,\n",
    "        progress=True\n",
    "    ).features,\n",
    "    priors=priors,\n",
    "    num_classes=10,\n",
    "    feature_map_depth=1280  # Profondeur de la feature map du MobileNet\n",
    ").to(DEVICE)\n",
    "\n",
    "detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boucle de train et validation\n",
    "\n",
    "Note: un modèle de type `YoloDetector` change de comportement entre le train et le test:\n",
    "- Pendant le train, appeler le modèle en passant les GT retourne directement la loss.\n",
    "- Pendant le test, le modèle retourne les boîtes décodées.\n",
    "\n",
    "Les détections sont représentées sour la forme d'un dictionnaire\n",
    "- `\"boxes\"`: les bounding boxes dans le format _xywh_\n",
    "- `\"scores\"`: un vecteur des scores de chaque boîte\n",
    "- `\"labels\"`: un vecteur des labels de chaque boîte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(\n",
    "    detector: YoloDetector,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: optim.Optimizer,\n",
    "    image_transforms: torch.nn.Module,\n",
    "    device: torch.device\n",
    ") -> float:\n",
    "    \"\"\"Run a single train epoch.\n",
    "\n",
    "    Args:\n",
    "        detector (YoloDetector): Yolo model.\n",
    "        data_loader (DataLoader): Torch data loader.\n",
    "        optimizer (Optimizer): Torch optimizer.\n",
    "        image_transforms (nn.Module): Transforms applied to the image.\n",
    "        device (torch.device): Model device.\n",
    "\n",
    "    Returns:\n",
    "        float: Average loss over the epoch.\n",
    "    \"\"\"\n",
    "    detector.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for images, targets in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        images = images.to(device)\n",
    "        images = image_transforms(images)\n",
    "\n",
    "        loss = detector(images, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def validation_step(\n",
    "    detector: YoloDetector,\n",
    "    data_loader: DataLoader,\n",
    "    image_transforms: torch.nn.Module,\n",
    "    device: torch.device,\n",
    "    scheduler: optim.lr_scheduler.LRScheduler | None = None\n",
    ") -> float:\n",
    "    \"\"\"Run a single validation step.\n",
    "\n",
    "    Args:\n",
    "        detector (YoloDetector): Yolo model.\n",
    "        data_loader (DataLoader): Torch data loader.\n",
    "        image_transforms (nn.Module): Transforms applied to the image.\n",
    "        device (torch.device): Model device.\n",
    "        scheduler (LRScheduler, optional): Learning scheduler\n",
    "\n",
    "    Returns:\n",
    "        float: mAP over the validation set.\n",
    "    \"\"\"\n",
    "    detector.eval()\n",
    "\n",
    "    # L'objet ci-dessous est un wrapper autour de la lib `pycocotools`. pycocotools est\n",
    "    # une library qui n'est pas très pratique à utiliser, mais implemente les fonctions\n",
    "    # pour le calcul de la mAP, ce wrapper permet d'eviter tout le boilerplate\n",
    "    # necessaire.\n",
    "    evaluator = CocoEvaluator()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader):\n",
    "            images = images.to(device)\n",
    "            images = image_transforms(images)\n",
    "\n",
    "            detections = detector(images)\n",
    "\n",
    "            for detection, target in zip(detections, targets):\n",
    "                evaluator.add_detections(detection, target)\n",
    "\n",
    "    metrics = evaluator.compute_metrics()\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step(metrics)\n",
    "\n",
    "    return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametrage de l'entrainement\n",
    "\n",
    "On utilise Adam comme optimizer, avec un scheduler pour réduire le learning rate lorsque la mAP n'augmente plus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12  # A choisir en fonction de la GPU\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "optimizer = optim.Adam(detector.parameters(), lr=learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\")\n",
    "\n",
    "# Valeurs de normalisation utilisées par le MobileNet.\n",
    "image_transforms = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "best_checkpoint = None\n",
    "best_map = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.39it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.99\n",
      "Validation mAP: 0.40\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.37it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 10.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.92\n",
      "Validation mAP: 0.21\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.39it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 12.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.85\n",
      "Validation mAP: 0.30\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.37it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.78\n",
      "Validation mAP: 0.38\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.37it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 12.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.90\n",
      "Validation mAP: 0.25\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.37it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.81\n",
      "Validation mAP: 0.32\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.39it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.69\n",
      "Validation mAP: 0.23\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.39it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 10.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.67\n",
      "Validation mAP: 0.24\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.37it/s]\n",
      "100%|██████████| 42/42 [00:03<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.65\n",
      "Validation mAP: 0.06\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417/417 [01:17<00:00,  5.37it/s]\n",
      "100%|██████████| 42/42 [00:04<00:00, 10.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss over the epoch: 0.62\n",
      "Validation mAP: 0.03\n",
      "Training done!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    loss = train_step(detector, train_loader, optimizer, image_transforms, DEVICE)\n",
    "    metrics = validation_step(detector, val_loader, image_transforms, DEVICE, scheduler)\n",
    "\n",
    "    print(f\"Train loss over the epoch: {loss:.2f}\")\n",
    "    print(f\"Validation mAP: {metrics:.2f}\")\n",
    "\n",
    "    if metrics > best_map:\n",
    "        best_map = metrics\n",
    "        torch.save(detector.state_dict(), \"checkpoint.pth\")\n",
    "\n",
    "print(\"Training done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation des resultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:03<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation mAP: 0.40\n"
     ]
    }
   ],
   "source": [
    "detector.load_state_dict(torch.load(\"checkpoint.pth\"))\n",
    "detector.eval()\n",
    "\n",
    "metrics = validation_step(detector, val_loader, image_transforms, DEVICE, scheduler)\n",
    "print(f\"Validation mAP: {metrics:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.display_boxes import display_image_with_boxes\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "path_image = os.path.join(path_val_images, random.choice(os.listdir(path_val_images)))\n",
    "\n",
    "image = cv2.imread(path_image)\n",
    "image_torch = torch.from_numpy(image).to(torch.float32)\n",
    "image_torch = torch.moveaxis(image_torch, -1, 0) / 255\n",
    "image_torch = image_torch.unsqueeze(0)\n",
    "image_torch = image_transforms(image_torch)\n",
    "image_torch = image_torch.to(DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    detector.eval()\n",
    "    detections = detector(image_torch)[0]\n",
    "\n",
    "detections = filter_by_score(detections, 0.3)\n",
    "detections = non_maximum_suppression(detections)\n",
    "\n",
    "image_with_detections = display_image_with_boxes(\n",
    "    image,\n",
    "    boxes=detections[\"boxes\"],\n",
    "    labels=detections[\"labels\"],\n",
    "    scores=detections[\"scores\"],\n",
    "    mode=\"xywh\",\n",
    "    display_labels=True,\n",
    "    scaling_factor=5\n",
    ")\n",
    "\n",
    "plt.imshow(image_with_detections)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
